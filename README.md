# GPT-Decoded
An implementation of the GPT(generative pretrained transformer) model, from scratch,  which produces Shakespearean text by training on the dialogues written by Shakespeare along with the GPT Encoder.
`NanoGPT` jupyter notebook has the behind the scenes implementation and some examples code runs which was done to get an understanding of the attention mechanism and the network.
`models.py` has the whole model sketched.
`attention.py` has the attention layer along with the other required layers.
`utils.py` has all the necessary functions.
`train.py` has the training loop.


BOd ROHAND:
I think shall brother yourself eyes:
One to my grace is thus with collate.

PRINCE EDWARD:
Brother, the changeness of Gloucester!

HASTYBALT:
Headness sort at Angelo ask all.

CAPTOPn:
A late, in plot his name wish'd land war;
His open his sen.

ServantBhum,
And well't well hen it again.

GREGORY:
Why, were it, sir.

FRIAR LAURENCE:
The king of God's bapy:
My name, queens Lovels of the date sleep.

RANCIDIO:
The homeo creat that learn art for our mistrument.

THurdered:
Takpet the realm we slave; when we have
slike song was nothing wooing.

HASTINGS:
Give my happ, my liege and for me; where I seek thee
Earth hath reven but in heavy others!
Even who goest away, I was sinfused.

CAMILLO:
No, for this is hold my love be thint in it.

HENRY BOLINGBROKE:
My maum absta my name; I'll comfort me to death.

KING RICHARD III:
He did by this odd of her high.

CAPITES:
Look of: hie I sit be must you are.
We'll profer them let me sold. To this lapleath!
Give me when my heart, and that 
